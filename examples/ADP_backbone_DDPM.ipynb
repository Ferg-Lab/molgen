{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from molgen.models import DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_fname = '/project/andrewferguson/Kirill/CMSC-35450/data_mdshare/alanine-dipeptide-nowater.pdb'\n",
    "trj_fnames = [str(i) for i in Path('/project/andrewferguson/Kirill/CMSC-35450/data_mdshare').glob('alanine-dipeptide-*-250ns-nowater.xtc')]\n",
    "trjs  = [md.load(t, top=pdb_fname).center_coordinates() for t in trj_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([250000, 24]), torch.Size([250000, 2]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz = list()\n",
    "phi_psi = list()\n",
    "for trj in trjs:\n",
    "    \n",
    "    t_backbone = trj.atom_slice(trj.top.select('backbone')).center_coordinates()\n",
    "    \n",
    "    n = trj.xyz.shape[0]\n",
    "    \n",
    "    _, phi = md.compute_phi(trj)\n",
    "    _, psi = md.compute_psi(trj)\n",
    "    \n",
    "    xyz.append(torch.tensor(t_backbone.xyz.reshape(n, -1)).float())\n",
    "    phi_psi.append(torch.tensor(np.concatenate((phi, psi), -1)).float())\n",
    "    \n",
    "xyz[0].shape, phi_psi[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DDPM(xyz[0].shape[1], phi_psi[0].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/andrewferguson/Kirill/class_project_env/lib/python3.7/site-packages/lightning_lite/plugins/environments/slurm.py:170: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /project/andrewferguson/Kirill/class_project_env/lib ...\n",
      "  category=PossibleUserWarning,\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type              | Params\n",
      "--------------------------------------------------------\n",
      "0 | model             | GaussianDiffusion | 4.0 M \n",
      "1 | ema_model         | GaussianDiffusion | 4.0 M \n",
      "2 | _feature_scaler   | MinMaxScaler      | 0     \n",
      "3 | _condition_scaler | MinMaxScaler      | 0     \n",
      "--------------------------------------------------------\n",
      "7.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 M     Total params\n",
      "31.749    Total estimated model params size (MB)\n",
      "/project/andrewferguson/Kirill/class_project_env/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee655705010142439220aaa2bcfdd622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DDPM(\n",
       "  (model): GaussianDiffusion(\n",
       "    (denoise_fn): Unet1D(\n",
       "      (init_conv): Conv1d(1, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (time_mlp): Sequential(\n",
       "        (0): SinusoidalPosEmb()\n",
       "        (1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (downs): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(32, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(32, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(64, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (ups): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(384, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(384, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(256, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "            (1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(192, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(192, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(192, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(192, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "            (1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(96, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(96, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(96, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(96, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(64, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "            (1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(32, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (mid_block1): ResnetBlock(\n",
       "        (mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (mid_attn): Residual(\n",
       "        (fn): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (to_qkv): Conv1d(256, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (to_out): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norm): LayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (mid_block2): ResnetBlock(\n",
       "        (mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (final_res_block): ResnetBlock(\n",
       "        (mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (proj): WeightStandardizedConv2d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (final_conv): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (ema_model): GaussianDiffusion(\n",
       "    (denoise_fn): Unet1D(\n",
       "      (init_conv): Conv1d(1, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (time_mlp): Sequential(\n",
       "        (0): SinusoidalPosEmb()\n",
       "        (1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (downs): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(32, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(32, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(64, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (ups): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(384, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(384, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(256, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "            (1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(192, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(192, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(192, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(192, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "            (1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(96, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(96, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(96, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(96, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(64, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "            (1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (proj): WeightStandardizedConv2d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (fn): LinearAttention(\n",
       "                (to_qkv): Conv1d(32, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (mid_block1): ResnetBlock(\n",
       "        (mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (mid_attn): Residual(\n",
       "        (fn): PreNorm(\n",
       "          (fn): Attention(\n",
       "            (to_qkv): Conv1d(256, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (to_out): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norm): LayerNorm()\n",
       "        )\n",
       "      )\n",
       "      (mid_block2): ResnetBlock(\n",
       "        (mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (final_res_block): ResnetBlock(\n",
       "        (mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (proj): WeightStandardizedConv2d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (proj): WeightStandardizedConv2d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (norm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (final_conv): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (_feature_scaler): MinMaxScaler()\n",
       "  (_condition_scaler): MinMaxScaler()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xyz, phi_psi, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4270657d39d41f18238838067e08e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae7ea85de4046418551126ecee16e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget(max_frame=749999)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nglview as nv\n",
    "trj_backbones = md.join([trj.atom_slice(trj.top.select('backbone')) for trj in trjs])\n",
    "v = nv.show_mdtraj(trj_backbones)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f137dd6b19cb42aeb39176fce72b2b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#xyz = model.generate(torch.cat(phi_psi))\n",
    "xyz = model.generate(torch.cat(phi_psi)[::1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mdtraj.Trajectory with 750 frames, 8 atoms, 3 residues, without unitcells at 0x7f8ff062e6a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz = xyz.reshape(xyz.size(0), -1, 3)\n",
    "fake_trj = md.Trajectory(xyz = xyz.cpu().numpy(), topology = trj_backbones.top)\n",
    "fake_trj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64afbb1e96248ce9b8fdbd418cb789e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget(max_frame=749)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = nv.show_mdtraj(fake_trj)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:class_project_env]",
   "language": "python",
   "name": "conda-env-class_project_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
